{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîÑ Deteksi Code-Switching dengan Naive Bayes & TF-IDF\n",
                "\n",
                "**Judul Skripsi:** Implementasi Naive Bayes dan TF-IDF untuk Deteksi Kode-Switching Bahasa Indonesia-Inggris pada Teks Media Sosial\n",
                "\n",
                "---\n",
                "\n",
                "## üìö Library yang Digunakan\n",
                "\n",
                "| Library | Fungsi |\n",
                "|---------|--------|\n",
                "| `pandas` | Manipulasi data tabular |\n",
                "| `numpy` | Operasi numerik |\n",
                "| `re` | Regular expression untuk preprocessing |\n",
                "| `matplotlib` | Visualisasi confusion matrix |\n",
                "| `seaborn` | Heatmap visualization |\n",
                "| `sklearn` | Machine learning pipeline |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.pipeline import make_pipeline\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "print(\"Library berhasil dimuat!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# üìå TAHAP 1: WEAK SUPERVISION (PELABELAN OTOMATIS)\n",
                "\n",
                "Pada tahap ini, kita akan melabeli data secara otomatis menggunakan **lexicon-based approach**."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Memuat Dataset Mentah"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Untuk Google Colab: Upload file terlebih dahulu\n",
                "# from google.colab import files\n",
                "# uploaded = files.upload()\n",
                "\n",
                "try:\n",
                "    df = pd.read_csv('codeswitch_emotion.csv', on_bad_lines='skip')\n",
                "    print(f\"[INFO] Dataset berhasil dimuat: {len(df)} baris\")\n",
                "    display(df.head())\n",
                "except FileNotFoundError:\n",
                "    print(\"[ERROR] File tidak ditemukan. Menggunakan data dummy.\")\n",
                "    df = pd.DataFrame({'tweet': [\n",
                "        \"Aku stuck banget sama deadline tugas\", \n",
                "        \"I love you so much\", \n",
                "        \"Makan nasi goreng enak di kantin\"\n",
                "    ]})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Definisi Lexicon (Kamus Kata)\n",
                "\n",
                "Lexicon berisi kata-kata penanda untuk masing-masing bahasa.\n",
                "\n",
                "**Catatan Penting:**\n",
                "- Kata-kata **ambiguous** (yang sering muncul di kedua konteks) telah dihapus\n",
                "- Contoh kata yang dihapus: `in`, `on`, `as`, `be`, `so`, `good`, `bad`, `not`, `no`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lexicon Bahasa Indonesia\n",
                "indo_markers = {\n",
                "    # Kata Ganti & Tunjuk\n",
                "    'aku', 'kamu', 'dia', 'kita', 'mereka', 'ini', 'itu', 'sini', 'situ', 'sana',\n",
                "    'gue', 'lu', 'lo', 'gw', 'anda', 'saya', 'kalian',\n",
                "    # Kata Sambung & Depan\n",
                "    'dan', 'atau', 'tapi', 'tetapi', 'karena', 'krn', 'jika', 'kalau', 'kalo', \n",
                "    'yang', 'yg', 'dari', 'pada', 'dalam', 'untuk', 'utk', 'buat', \n",
                "    'dengan', 'dgn', 'sama', 'bisa', 'dapat', 'akan', 'ingin', 'mau', 'sudah', \n",
                "    'telah', 'sedang', 'lagi', 'lg', 'masih', 'belum', 'blm',\n",
                "    # Kata Tanya & Seru\n",
                "    'apa', 'kenapa', 'knp', 'mengapa', 'gimana', 'bagaimana', 'siapa', 'kapan', \n",
                "    'dimana', 'kok', 'sih', 'dong', 'deh', 'kan', 'yuk', 'wkwk', 'hehe', 'haha',\n",
                "    'wah', 'nah', 'loh', 'lah', 'kah', 'pun',\n",
                "    # Kata Kerja & Sifat Umum\n",
                "    'makan', 'minum', 'tidur', 'jalan', 'lihat', 'dengar', 'baca', 'tulis', \n",
                "    'beli', 'jual', 'bayar', 'kerja', 'suka', 'cinta', 'benci', 'marah',\n",
                "    'senang', 'sedih', 'takut', 'berani', 'malu', 'bangga', 'bagus', 'jelek',\n",
                "    'baik', 'jahat', 'benar', 'salah', 'cepat', 'lambat', 'mahal', 'murah',\n",
                "    'terima', 'kasih', 'tolong', 'maaf', 'selamat', 'pagi', 'siang', 'malam',\n",
                "    'rumah', 'orang', 'anak', 'hari', 'tahun', 'waktu', 'uang', 'harga',\n",
                "    'tidak', 'tak', 'gak', 'ga', 'nggak', 'bukan', 'jangan', 'usah', 'udah'\n",
                "}\n",
                "\n",
                "print(f\"Total kata Indonesia: {len(indo_markers)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lexicon Bahasa Inggris (kata ambiguous dihapus)\n",
                "eng_markers = {\n",
                "    # Pronouns & Prepositions\n",
                "    'i', 'you', 'he', 'she', 'we', 'they', 'this', 'that', 'these', 'those',\n",
                "    'my', 'your', 'his', 'her', 'our', 'their', 'mine', 'yours',\n",
                "    'for', 'with', 'from', 'about', 'into', 'through', 'after', 'over', 'between', 'against',\n",
                "    # Conjunctions & Auxiliary Verbs\n",
                "    'and', 'because', 'when', 'where', 'why', 'how',\n",
                "    'is', 'am', 'are', 'was', 'were', 'been', 'being',\n",
                "    'have', 'has', 'had', 'does', 'did', 'done',\n",
                "    'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must',\n",
                "    # Common Verbs\n",
                "    'want', 'need', 'know', 'think', 'take', 'see', 'get', 'give', 'come',\n",
                "    'make', 'look', 'use', 'find', 'tell', 'ask', 'seem', 'feel', 'try',\n",
                "    'leave', 'call', 'drink', 'eat', 'sleep', 'run', 'walk', 'talk', 'speak',\n",
                "    'say', 'help', 'start', 'stop', 'move', 'write', 'read', 'pay', 'buy', 'sell',\n",
                "    # Adjectives & Adverbs\n",
                "    'great', 'high', 'low', 'big', 'small', 'long', 'short',\n",
                "    'new', 'old', 'right', 'wrong', 'happy', 'sad', 'angry', 'afraid', 'brave',\n",
                "    'beautiful', 'ugly', 'expensive', 'cheap', 'fast', 'slow', 'hard', 'soft',\n",
                "    'actually', 'literally', 'basically', 'totally', 'honestly', 'probably',\n",
                "    'maybe', 'please', 'thanks', 'sorry', 'excuse', 'hello', 'bye',\n",
                "    'yeah', 'yep', 'nope', 'never', 'always', 'ever',\n",
                "    'people', 'life', 'man', 'woman', 'love', 'really', 'very', 'just'\n",
                "}\n",
                "\n",
                "print(f\"Total kata Inggris: {len(eng_markers)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Fungsi Pelabelan Otomatis (Ratio-Based)\n",
                "\n",
                "**Algoritma Pelabelan:**\n",
                "\n",
                "1. Hitung jumlah kata Indonesia (`id_score`) dan Inggris (`en_score`)\n",
                "2. Hitung rasio masing-masing bahasa\n",
                "3. Tentukan label berdasarkan kriteria:\n",
                "\n",
                "| Kondisi | Label |\n",
                "|---------|-------|\n",
                "| `id_score >= 2` AND `en_score >= 2` AND rasio seimbang (25-75%) | **MIX** |\n",
                "| `en_ratio > 0.6` OR (`en_score >= 2` AND `id_score == 0`) | **EN** |\n",
                "| Lainnya | **ID** |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def automated_labeling(text):\n",
                "    \"\"\"\n",
                "    Pelabelan otomatis dengan threshold berbasis RASIO.\n",
                "    MIX hanya jika kedua bahasa cukup seimbang (25-75%) DAN minimal 2 kata masing-masing.\n",
                "    \"\"\"\n",
                "    if not isinstance(text, str): \n",
                "        return 'ID'\n",
                "    \n",
                "    text_clean = text.lower()\n",
                "    text_clean = re.sub(r'[^a-z\\s]', ' ', text_clean)\n",
                "    words = text_clean.split()\n",
                "    \n",
                "    if len(words) == 0: \n",
                "        return 'ID'\n",
                "    \n",
                "    word_set = set(words)\n",
                "    id_score = len(word_set.intersection(indo_markers))\n",
                "    en_score = len(word_set.intersection(eng_markers))\n",
                "    \n",
                "    total_markers = id_score + en_score\n",
                "    \n",
                "    # Jika tidak ada marker sama sekali, default ke ID\n",
                "    if total_markers == 0: \n",
                "        return 'ID'\n",
                "    \n",
                "    # Hitung rasio\n",
                "    id_ratio = id_score / total_markers\n",
                "    en_ratio = en_score / total_markers\n",
                "    \n",
                "    # MIX: kedua bahasa harus cukup seimbang (25-75%) DAN minimal 2 kata masing-masing\n",
                "    if id_score >= 2 and en_score >= 2 and 0.25 <= id_ratio <= 0.75:\n",
                "        return 'MIX'\n",
                "    # EN: mayoritas marker adalah English\n",
                "    elif en_ratio > 0.6 or (en_score >= 2 and id_score == 0):\n",
                "        return 'EN'\n",
                "    # ID: default atau mayoritas Indonesia\n",
                "    else:\n",
                "        return 'ID'\n",
                "\n",
                "# Test fungsi\n",
                "test_cases = [\n",
                "    \"Aku capek sekali\",\n",
                "    \"I love you so much\",\n",
                "    \"Aku stuck banget sama deadline tugas\"\n",
                "]\n",
                "\n",
                "print(\"Test Pelabelan:\")\n",
                "for text in test_cases:\n",
                "    print(f\"  '{text}' ‚Üí {automated_labeling(text)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Menerapkan Pelabelan ke Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"[...] Sedang menjalankan algoritma pelabelan otomatis...\")\n",
                "df['label_bahasa'] = df['tweet'].apply(automated_labeling)\n",
                "print(\"[‚úì] Pelabelan selesai!\")\n",
                "\n",
                "# Tampilkan statistik\n",
                "print(\"\\nüìä Distribusi Label:\")\n",
                "stats = df['label_bahasa'].value_counts()\n",
                "total = len(df)\n",
                "for label, count in stats.items():\n",
                "    print(f\"  {label}: {count} ({count/total:.1%})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisasi distribusi label\n",
                "plt.figure(figsize=(8, 5))\n",
                "colors = ['#4CAF50', '#2196F3', '#FF9800']\n",
                "df['label_bahasa'].value_counts().plot(kind='bar', color=colors, edgecolor='black')\n",
                "plt.title('Distribusi Label Bahasa', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Label')\n",
                "plt.ylabel('Jumlah')\n",
                "plt.xticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Menyimpan Dataset Hasil Pelabelan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output_csv = 'dataset_hasil_pelabelan.csv'\n",
                "df[['tweet', 'label_bahasa']].to_csv(output_csv, index=False)\n",
                "print(f\"[‚úì] File '{output_csv}' berhasil disimpan!\")\n",
                "\n",
                "# Untuk Google Colab: Download file\n",
                "# from google.colab import files\n",
                "# files.download(output_csv)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# üìå TAHAP 2: PELATIHAN MODEL NAIVE BAYES\n",
                "\n",
                "Pada tahap ini, kita akan melatih model klasifikasi menggunakan:\n",
                "- **TF-IDF Vectorizer**: Mengubah teks menjadi vektor numerik\n",
                "- **Multinomial Naive Bayes**: Algoritma klasifikasi probabilistik"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Preprocessing Teks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_text_final(text):\n",
                "    \"\"\"\n",
                "    Membersihkan teks untuk input model.\n",
                "    - Lowercase\n",
                "    - Hapus username dan URL placeholder\n",
                "    - Hapus karakter non-alfanumerik\n",
                "    \"\"\"\n",
                "    text = str(text).lower()\n",
                "    text = re.sub(r'\\[username\\]|\\[url\\]', '', text)\n",
                "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
                "    return text.strip()\n",
                "\n",
                "df['text_clean'] = df['tweet'].apply(clean_text_final)\n",
                "print(\"[‚úì] Preprocessing selesai!\")\n",
                "display(df[['tweet', 'text_clean', 'label_bahasa']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Split Data Training dan Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    df['text_clean'], \n",
                "    df['label_bahasa'], \n",
                "    test_size=0.2, \n",
                "    random_state=42,\n",
                "    stratify=df['label_bahasa']\n",
                ")\n",
                "\n",
                "print(f\"Data Training: {len(X_train)} sampel\")\n",
                "print(f\"Data Testing : {len(X_test)} sampel\")\n",
                "print(f\"\\nDistribusi Training:\")\n",
                "print(y_train.value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Oversampling untuk Menyeimbangkan Kelas\n",
                "\n",
                "Kita menggunakan **oversampling** untuk mengatasi ketidakseimbangan kelas.\n",
                "Setiap kelas akan didup likasi hingga memiliki jumlah yang sama dengan kelas mayoritas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"[...] Melakukan oversampling untuk menyeimbangkan kelas...\")\n",
                "\n",
                "train_df = pd.DataFrame({'text': X_train.values, 'label': y_train.values})\n",
                "\n",
                "# Hitung jumlah sampel per kelas\n",
                "class_counts = train_df['label'].value_counts()\n",
                "max_count = class_counts.max()\n",
                "print(f\"\\nSebelum oversampling:\")\n",
                "print(class_counts)\n",
                "\n",
                "# Oversample setiap kelas agar seimbang\n",
                "balanced_dfs = []\n",
                "for label in class_counts.index:\n",
                "    class_df = train_df[train_df['label'] == label]\n",
                "    oversampled = class_df.sample(n=max_count, replace=True, random_state=42)\n",
                "    balanced_dfs.append(oversampled)\n",
                "\n",
                "train_balanced = pd.concat(balanced_dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "X_train = train_balanced['text']\n",
                "y_train = train_balanced['label']\n",
                "\n",
                "print(f\"\\nSesudah oversampling:\")\n",
                "print(y_train.value_counts())\n",
                "print(f\"\\n[‚úì] Data training diseimbangkan: {len(train_balanced)} sampel ({max_count} per kelas)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Melatih Model\n",
                "\n",
                "**Pipeline:**\n",
                "1. **TfidfVectorizer**: `ngram_range=(1,2)`, `max_features=5000`\n",
                "2. **MultinomialNB**: `alpha=0.1` (smoothing parameter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = make_pipeline(\n",
                "    TfidfVectorizer(ngram_range=(1, 2), max_features=5000), \n",
                "    MultinomialNB(alpha=0.1)\n",
                ")\n",
                "\n",
                "print(\"[...] Sedang melatih model...\")\n",
                "model.fit(X_train, y_train)\n",
                "print(\"[‚úì] Model berhasil dilatih!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# üìå TAHAP 3: EVALUASI & VISUALISASI"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Menghitung Akurasi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "\n",
                "print(\"\\n\" + \"*\"*40)\n",
                "print(\" AKURASI MODEL \".center(40, \"*\"))\n",
                "print(f\"{acc_score:.2%}\".center(40))\n",
                "print(\"*\"*40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Classification Report\n",
                "\n",
                "| Metrik | Deskripsi |\n",
                "|--------|----------|\n",
                "| **Precision** | Dari prediksi positif, berapa yang benar |\n",
                "| **Recall** | Dari label sebenarnya, berapa yang terdeteksi |\n",
                "| **F1-Score** | Harmonic mean dari precision dan recall |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nüìä Detail Laporan Klasifikasi:\")\n",
                "print(classification_report(y_test, y_pred, zero_division=0))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_test, y_pred, labels=['ID', 'EN', 'MIX'])\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['ID', 'EN', 'MIX'], \n",
                "            yticklabels=['ID', 'EN', 'MIX'])\n",
                "plt.title('Confusion Matrix: Deteksi Code-Switching', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('Label Asli (Weak Supervision)')\n",
                "plt.xlabel('Prediksi Model')\n",
                "plt.tight_layout()\n",
                "plt.savefig('confusion_matrix.png', dpi=150)\n",
                "print(\"[‚úì] Gambar 'confusion_matrix.png' berhasil disimpan.\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Test Prediksi Manual"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_sentences = [\n",
                "    \"Aku capek sekali\",\n",
                "    \"I love you so much\",\n",
                "    \"you and they\",\n",
                "    \"Aku stuck banget sama deadline tugas\",\n",
                "    \"Which is sebenernya dia fine aja\"\n",
                "]\n",
                "\n",
                "print(\"\\nüîç Test Prediksi Model:\")\n",
                "print(\"-\" * 60)\n",
                "for sentence in test_sentences:\n",
                "    clean = clean_text_final(sentence)\n",
                "    pred = model.predict([clean])[0]\n",
                "    prob = model.predict_proba([clean])[0]\n",
                "    print(f\"'{sentence}'\")\n",
                "    print(f\"  ‚Üí Prediksi: {pred}\")\n",
                "    print(f\"  ‚Üí Probabilitas: ID={prob[1]:.1%}, EN={prob[0]:.1%}, MIX={prob[2]:.1%}\")\n",
                "    print()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}